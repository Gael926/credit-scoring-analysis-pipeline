# Credit Scoring - PrÃ©diction de DÃ©faut de Paiement

Pipeline complet de machine learning pour la prÃ©diction du risque de dÃ©faut de crÃ©dit, basÃ© sur les donnÃ©es du challenge [Home Credit Default Risk](https://www.kaggle.com/c/home-credit-default-risk).

L'objectif principal n'Ã©tait pas de maximiser l'AUC comme dans les compÃ©titions Kaggle classiques, mais d'**optimiser directement le CoÃ»t MÃ©tier**. Cette approche reflÃ¨te la rÃ©alitÃ© Ã©conomique : un dÃ©faut non dÃ©tectÃ© (Faux NÃ©gatif) coÃ»te bien plus cher qu'un refus abusif (Faux Positif).

**[ğŸ‘‰ Tester l'application](https://credit-scoring-analysis-pipeline.streamlit.app/)**

![Dashboard Preview](reports/figures/global_dashboard_screenshot.png)

## CoÃ»t MÃ©tier : L'Indicateur ClÃ©

La fonction objectif a Ã©tÃ© paramÃ©trÃ©e pour reflÃ©ter l'asymÃ©trie des risques :

| Type d'Erreur | CoÃ»t | Explication |
|---------------|------|-------------|
| **Faux NÃ©gatif** (dÃ©faut non dÃ©tectÃ©) | **10** | Perte du capital prÃªtÃ© |
| **Faux Positif** (refus abusif) | **1** | OpportunitÃ© commerciale perdue |

Cette pondÃ©ration 10:1 pousse le modÃ¨le vers un **recall Ã©levÃ©** (dÃ©tection maximale des dÃ©fauts) tout en contrÃ´lant les refus abusifs.


## Contexte et DonnÃ©es

Le dataset Home Credit comprend **10 fichiers distincts** totalisant plus de 30 millions de lignes :

| Fichier | Description | Volume |
|---------|-------------|--------|
| `application_train.csv` | DonnÃ©es principales des demandeurs | 307k |
| `application_test.csv` | DonnÃ©es de test | 48k |
| `bureau.csv` | Historique de crÃ©dit (autres institutions) | 1.7M |
| `bureau_balance.csv` | Soldes mensuels bureau | 27M |
| `previous_application.csv` | Demandes prÃ©cÃ©dentes Home Credit | 1.6M |
| `POS_CASH_balance.csv` | Soldes crÃ©dits POS | 10M |
| `credit_card_balance.csv` | Soldes cartes de crÃ©dit | 3.8M |
| `installments_payments.csv` | Historique de paiements | 13.6M |
| `HomeCredit_columns_description.csv` | Dictionnaire des variables | - |
| `sample_submission.csv` | Format de soumission | - |

La difficultÃ© principale rÃ©side dans l'**agrÃ©gation intelligente** de ces sources pour crÃ©er des features pertinentes au niveau client.

## Feature Engineering

Deux versions du dataset ont Ã©tÃ© crÃ©Ã©es :
- **V1** : Conservation de toutes les colonnes, y compris celles avec >50% de valeurs manquantes
- **V2** : Suppression des colonnes inutiles ou trop vides (habitat, documents)

### Ratios Financiers
```python
CREDIT_INCOME_PERCENT = AMT_CREDIT / AMT_INCOME_TOTAL
ANNUITY_INCOME_PERCENT = AMT_ANNUITY / AMT_INCOME_TOTAL
CREDIT_TO_GOODS_RATIO = AMT_CREDIT / AMT_GOODS_PRICE
```

### AgrÃ©gations des Tables Externes
- **Bureau** : Nombre de crÃ©dits actifs, montant total dÃ», retards moyens
- **Previous Applications** : Taux d'acceptation, montants moyens demandÃ©s
- **Installments** : Retards de paiement, Ã©carts entre dÃ» et payÃ©
- **POS/Cash** : Nombre de mensualitÃ©s restantes, statut des crÃ©dits

### Encodage
- **One-Hot Encoding** pour les variables nominales
- **Label Encoding** pour les variables ordinales

Le rÃ©sultat : passage de ~120 features brutes Ã  **180+ features enrichies**.

## ModÃ©lisation

### Benchmark des ModÃ¨les

L'entraÃ®nement initial a identifiÃ© **LightGBM** comme l'algorithme le plus performant :

| ModÃ¨le | AUC | CoÃ»t MÃ©tier |
|--------|-----|-------------|
| Dummy | 0.50 | 35 000 |
| Random Forest | 0.73 | 23 000 |
| XGBoost | 0.76 | 22 500 |
| **LightGBM** | **0.788** | **21 200** |

Les performances Ã©taient similaires entre V1 et V2, la V2 a Ã©tÃ© retenue pour sa lÃ©gÃ¨retÃ©.

### Optimisation Optuna

L'optimisation des hyperparamÃ¨tres via **Optuna** a ciblÃ© uniquement la minimisation du CoÃ»t MÃ©tier sur l'ensemble de validation, garantissant que le modÃ¨le converge vers la solution la plus rentable Ã©conomiquement.

Une approche par Validation CroisÃ©e (5 folds) avait Ã©tÃ© envisagÃ©e mais s'est avÃ©rÃ©e moins performante que le modÃ¨le LightGBM unique optimisÃ©.

## ExplicabilitÃ© SHAP

L'analyse SHAP assure la transparence requise pour un outil de credit scoring :

![SHAP Summary Plot](reports/figures/shap_global_summary.png)

**Variables dÃ©terminantes :**
- **Scores Externes (EXT_SOURCE_X)** : Variables les plus importantes, provenant de sources externes. Un score faible augmente significativement la probabilitÃ© de dÃ©faut.
- **Ã‚ge du Client (DAYS_BIRTH)** : Les clients plus jeunes sont associÃ©s Ã  un risque accru.
- **Montant de l'AnnuitÃ© (AMT_ANNUITY)** : Indicateur de la charge de remboursement mensuelle.

Ces variables confirment que le modÃ¨le prend ses dÃ©cisions selon des indicateurs de risque classiques, tout en optimisant le rendement financier via le CoÃ»t MÃ©tier.

## Dashboard Interactif

Le dashboard Streamlit permet deux usages :

### Audit Client
SÃ©lection d'un client existant pour vÃ©rifier la cohÃ©rence du modÃ¨le avec l'historique rÃ©el.

![Audit Client](reports/figures/audit_dashboard_screenshot.png)

### Simulateur de CrÃ©dit
Simulation d'une nouvelle demande avec des paramÃ¨tres ajustables :
- Revenu annuel, montant du crÃ©dit, prix du bien
- Ã‚ge et anciennetÃ© d'emploi
- DurÃ©e du prÃªt

Le modÃ¨le retourne une probabilitÃ© de dÃ©faut et un niveau de risque.

![Simulateur](reports/figures/simulation_dashboard_screenshot.png)

## Structure du Projet

```
â”œâ”€â”€ main.py                      # Pipeline complet (CLI)
â”œâ”€â”€ app_dashboard.py             # Dashboard Streamlit
â”œâ”€â”€ api_server.py                # API Flask pour le modÃ¨le
â”œâ”€â”€ docker-compose.yml           # Orchestration des services
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                # ParamÃ¨tres (coÃ»ts mÃ©tier, chemins)
â”‚   â”œâ”€â”€ data_prep.py             # Feature engineering
â”‚   â”œâ”€â”€ model_utils.py           # EntraÃ®nement et optimisation
â”‚   â”œâ”€â”€ metrics.py               # CoÃ»t mÃ©tier et mÃ©triques
â”‚   â””â”€â”€ explainability.py        # SHAP
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_v2_data_preparation   # Exploration et feature engineering
â”‚   â”œâ”€â”€ 02_model_training        # Benchmark et optimisation
â”‚   â”œâ”€â”€ 03_explainability        # Analyse SHAP
â”‚   â””â”€â”€ 04_mlflow_serving_test   # Test de l'API
â”‚
â”œâ”€â”€ tests/                       # Tests unitaires (pytest)
â”œâ”€â”€ models/                      # ModÃ¨les entraÃ®nÃ©s (.pkl)
â”œâ”€â”€ reports/figures/             # Graphiques SHAP
â””â”€â”€ dashboard_data/              # DonnÃ©es pour le dashboard
```

## Installation et ExÃ©cution

### Option 1 : Dashboard en ligne (Aucune installation)

**[ğŸ‘‰ AccÃ©der au Dashboard](https://credit-scoring-analysis-pipeline.streamlit.app/)**

---

### Option 2 : Docker (DÃ©veloppement local)

```bash
# Cloner le projet
git clone https://github.com/Gael926/credit-scoring-analysis-pipeline.git
cd credit-scoring-analysis-pipeline

# Lancer les services
docker compose up --build
```

| Service | URL |
|---------|-----|
| Dashboard | http://localhost:8501 |
| API ModÃ¨le | http://localhost:5001 |
| Jupyter | http://localhost:8888 |

---

### Option 3 : RÃ©-entraÃ®ner le modÃ¨le

```bash
pip install -r requirements.txt

# TÃ©lÃ©charger les donnÃ©es Kaggle dans data/raw/
# https://www.kaggle.com/c/home-credit-default-risk/data

python main.py --n-trials 50
```


## Technologies

- **ML** : LightGBM, Optuna, SHAP
- **Data** : Pandas, NumPy
- **Web** : Streamlit, Flask
- **MLOps** : MLflow, Docker
- **Tests** : Pytest

## RÃ©sultats

| MÃ©trique | Valeur |
|----------|--------|
| AUC ROC | 0.788 |
| CoÃ»t MÃ©tier | 21 200 (vs 35 000 baseline) |
| AmÃ©lioration | **~40%** de rÃ©duction du coÃ»t |

Le modÃ¨le privilÃ©gie la dÃ©tection des dÃ©fauts (faux nÃ©gatifs coÃ»teux) tout en maintenant un taux de faux positifs acceptable. La traÃ§abilitÃ© complÃ¨te est assurÃ©e par MLflow.