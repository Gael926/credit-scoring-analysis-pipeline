# Credit Scoring Model

Ce projet impl√©mente un pipeline complet de Credit Scoring, de la pr√©paration des donn√©es au d√©ploiement du mod√®le, en passant par l'entra√Ænement, l'optimisation et l'explicabilit√© (SHAP).

## Architecture du Pipeline

```mermaid
flowchart TD
    A[üìä Donn√©es CSV] --> B[üîß Feature Engineering]
    B --> C[üéØ Entra√Ænement LightGBM]
    C --> D[‚öôÔ∏è Optimisation Optuna]
    D --> E[üì¶ MLflow Tracking]
    E --> F[üöÄ Docker API]
    C --> G[üìà SHAP Explainability]
```


## Structure du Projet

- `data/` : Donn√©es brutes et proces√©es.
- `notebooks/` :
  - `01_v2_data_preparation.ipynb` : Pr√©paration des donn√©es (Feature Engineering).
  - `02_model_training.ipynb` : Entra√Ænement, Optimisation (Optuna) et Tracking (MLflow).
  - `03_explainability.ipynb` : Analyse SHAP (Globale et Locale).
  - `04_mlflow_serving_test.ipynb` : Test de l'API de pr√©diction.
- `src/` : Code modulaire (`model_utils.py`, `explainability.py`, etc.).
- `models/` : Artefacts des mod√®les entra√Æn√©s.
- `mlruns/` : Tracking MLflow local.
- `reports/` : Figures et analyses.

## Pr√©requis
- Python 3.11
- Docker Desktop (install√© et lanc√©) : [T√©l√©charger Docker Desktop](https://www.docker.com/products/docker-desktop/)

## Installation

1. Cloner le projet.
2. Installer les d√©pendances :
```bash
pip install -r requirements.txt
```
3. Lancer MLflow UI (optionnel pour visualiser les runs) :
```bash
mlflow ui
```

## √âtapes d'Ex√©cution

### 1. Entra√Ænement
Ouvrir et ex√©cuter `notebooks/01_v1_data_preparation.ipynb`.
Ouvrir et ex√©cuter `notebooks/01_v2_data_preparation.ipynb`.
- Pr√©paration des donn√©es (Feature Engineering).
- 2 versions de la pr√©paration des donn√©es diff√©rentes.

Ouvrir et ex√©cuter `notebooks/02_model_training.ipynb`.
- Entra√Æne plusieurs mod√®les (Dummy, Random Forest, XGBoost, LightGBM).
- R√©gression logistique via imputation.
- Optimise LightGBM avec Optuna.
- Sauvegarde le meilleur mod√®le dans `models/best_model.pkl` et `models/final_model` (format MLflow).

### 2. Explicabilit√©
Ouvrir et ex√©cuter `notebooks/03_explainability.ipynb`.
- G√©n√®re les graphiques SHAP (Global Feature Importance, Beeswarm).
- G√©n√®re des explications locales pour des clients sp√©cifiques.
- Les figures sont sauvegard√©es dans `reports/figures`.

### 3. D√©ploiement (Docker)
Le projet utilise Docker Compose pour lancer simultan√©ment :
1. **L'API de pr√©diction (MLflow)** sur le port `5000`.
2. **Un serveur Jupyter Notebook** sur le port `8888`.

**Lancer les services :**
```bash
docker compose up --build
```
*Note : Assurez-vous que Docker Desktop est lanc√©.*

- Acc√®s API : `http://localhost:5000`
- Acc√®s Jupyter : `http://localhost:8888` (le token est d√©sactiv√©)

Pour arr√™ter les services, faites `Ctrl+C` dans le terminal.

### 4. Test API
Ouvrir `notebooks/04_mlflow_serving_test.ipynb` pour envoyer des requ√™tes au conteneur Docker et obtenir des pr√©dictions.