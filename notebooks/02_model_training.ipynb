{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro_md",
            "metadata": {},
            "source": [
                "# 02. Entraînement et Sélection du Modèle Final\n",
                "\n",
                "Ce notebook implémente le workflow complet validé :\n",
                "1. **Benchmark Initial** : Comparer 4 modèles de base (Dummy, LogReg, RF, XGB) sur les datasets V1 et V2 pour choisir le meilleur dataset.\n",
                "2. **Sélection Dataset & Split** : On fixe le split (Train/Val/Test) du meilleur dataset identifié.\n",
                "3. **Optimisation LightGBM** : On optimise LightGBM uniquement sur ce dataset.\n",
                "4. **Cross-Validation** : On valide la robustesse avec une CV 5-folds sur le Train set.\n",
                "5. **Entraînement Final** : On réentraîne le modèle final sur Train+Val (optionnel) ou juste Train, puis on évalue sur Test.\n",
                "6. **Sauvegarde** : Modèle pour serving MLflow."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import mlflow\n",
                "import sys\n",
                "import os\n",
                "import joblib\n",
                "import shutil\n",
                "\n",
                "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
                "if project_root not in sys.path: sys.path.append(project_root)\n",
                "\n",
                "from src.model_utils import (\n",
                "    get_train_val_test_split,\n",
                "    train_dummy, train_logistic_regression, train_random_forest, \n",
                "    train_xgboost, train_lightgbm,\n",
                "    train_lightgbm_cv, optimize_lightgbm, COST_WEIGHTS\n",
                ")\n",
                "\n",
                "mlflow.set_tracking_uri(\"../mlruns\")\n",
                "mlflow.set_experiment(\"Credit_Scoring_Final_Workflow\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load_data",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Chargement V1/V2\n",
                "X_v1 = pd.read_pickle('../data/processed/X_prepared_v1.pkl')\n",
                "y_v1 = pd.read_pickle('../data/processed/y_prepared_v1.pkl')\n",
                "X_v2 = pd.read_pickle('../data/processed/X_prepared_v2.pkl')\n",
                "y_v2 = pd.read_pickle('../data/processed/y_prepared_v2.pkl')\n",
                "\n",
                "def clean_cols(df):\n",
                "    df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in df.columns]\n",
                "    return df\n",
                "X_v1 = clean_cols(X_v1)\n",
                "X_v2 = clean_cols(X_v2)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bench_md",
            "metadata": {},
            "source": [
                "## 1. Benchmark Rapide (Base Models)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "run_bench",
            "metadata": {},
            "outputs": [],
            "source": [
                "results = []\n",
                "\n",
                "# On stocke les données splittées pour pouvoir réutiliser celles du gagnant\n",
                "splits = {}\n",
                "\n",
                "for name, X, y in [(\"v1\", X_v1, y_v1), (\"v2\", X_v2, y_v2)]:\n",
                "    print(f\"--- Benchmarking Dataset {name} ---\")\n",
                "    Xt, yt, Xv, yv, Xte, yte = get_train_val_test_split(X, y)\n",
                "    splits[name] = (Xt, yt, Xv, yv, Xte, yte)\n",
                "    \n",
                "    # Dummy\n",
                "    _, m = train_dummy(Xt, yt, Xv, yv, Xte, yte, name)\n",
                "    results.append({\"Data\": name, \"Model\": \"Dummy\", **m})\n",
                "    \n",
                "    # LogReg\n",
                "    _, m = train_logistic_regression(Xt, yt, Xv, yv, Xte, yte, name)\n",
                "    results.append({\"Data\": name, \"Model\": \"LogReg\", **m})\n",
                "    \n",
                "    # RF\n",
                "    _, m = train_random_forest(Xt, yt, Xv, yv, Xte, yte, name)\n",
                "    results.append({\"Data\": name, \"Model\": \"RF\", **m})\n",
                "    \n",
                "    # XGB\n",
                "    _, m = train_xgboost(Xt, yt, Xv, yv, Xte, yte, name)\n",
                "    results.append({\"Data\": name, \"Model\": \"XGB\", **m})\n",
                "    \n",
                "    # LightGBM (Baseline)\n",
                "    _, m = train_lightgbm(Xt, yt, Xv, yv, Xte, yte, name)\n",
                "    results.append({\"Data\": name, \"Model\": \"LightGBM\", **m})\n",
                "\n",
                "df_res = pd.DataFrame(results).sort_values(\"business_cost\")\n",
                "display(df_res[[\"Data\", \"Model\", \"business_cost\", \"auc\", \"val_best_cost\"]])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "select_ds_md",
            "metadata": {},
            "source": [
                "## 2. Sélection du Dataset Gagnant pour l'Optimisation\n",
                "On prend le dataset qui a donné le meilleur score LightGBM (le modèle cible)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "select_data",
            "metadata": {},
            "outputs": [],
            "source": [
                "lgbm_res = df_res[df_res[\"Model\"] == \"LightGBM\"].sort_values(\"business_cost\")\n",
                "best_data_name = lgbm_res.iloc[0][\"Data\"]\n",
                "print(f\"Dataset sélectionné pour optimisation LightGBM : {best_data_name}\")\n",
                "\n",
                "# Récupération des splits EXISTANTS (pas de re-split)\n",
                "X_train, y_train, X_val, y_val, X_test, y_test = splits[best_data_name]\n",
                "print(f\"Shape Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "optuna_md",
            "metadata": {},
            "source": [
                "## 3. Optimisation Optuna LightGBM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "run_optuna",
            "metadata": {},
            "outputs": [],
            "source": [
                "best_params = optimize_lightgbm(X_train, y_train, X_val, y_val, n_trials=30)\n",
                "\n",
                "final_params = best_params.copy()\n",
                "final_params.update({\n",
                "    \"metric\": \"custom\", \"objective\": \"binary\", \"verbosity\": -1,\n",
                "    \"boosting_type\": \"gbdt\", \"random_state\": 42, \"n_jobs\": -1,\n",
                "    \"class_weight\": COST_WEIGHTS, \"n_estimators\": 1000\n",
                "})"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cv_md",
            "metadata": {},
            "source": [
                "## 4. Cross-Validation de Confirmation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "run_cv",
            "metadata": {},
            "outputs": [],
            "source": [
                "# On vérifie la stabilité sur le Train Set complet (si on voulait concatener train+val on pourrait, mais gardons Train)\n",
                "mean_auc, mean_cost = train_lightgbm_cv(X_train, y_train, params=final_params)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "train_final_md",
            "metadata": {},
            "source": [
                "## 5. Entraînement Final & Evaluation Test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "final_train",
            "metadata": {},
            "outputs": [],
            "source": [
                "# On entraîne le modèle final sur Train (avec Val pour early stopping) \n",
                "# et on évalue sur Test. C'est CE modèle qui part en prod.\n",
                "model_final, metrics_final = train_lightgbm(\n",
                "    X_train, y_train, X_val, y_val, X_test, y_test, \n",
                "    dataset_name=f\"{best_data_name}_OPTI_FINAL\", \n",
                "    params=final_params\n",
                ")\n",
                "\n",
                "print(\"METRICS FINALES SUR TEST:\", metrics_final)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "save_model",
            "metadata": {},
            "outputs": [],
            "source": [
                "if not os.path.exists(\"../models\"):\n",
                "    os.makedirs(\"../models\")\n",
                "\n",
                "joblib.dump(model_final, \"../models/best_model.pkl\")\n",
                "\n",
                "path_serving = \"../models/final_model\"\n",
                "if os.path.exists(path_serving): shutil.rmtree(path_serving)\n",
                "mlflow.lightgbm.save_model(model_final, path_serving)\n",
                "print(\"Modèle prêt pour Docker!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
